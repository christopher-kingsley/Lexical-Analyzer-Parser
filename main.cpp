// Christopher Kingsley, Ahmad Khader
// COMP 360
// Project 1 
// Lexical Analyzer and Recursive-Descending Parser

#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <cctype>
#include <algorithm> // For std::find

// Token types
const int Keyword = 0; // reserved words like int, for, float
const int Identifier = 1; // names defined by programmer
const int Constant = 2; // numerical values that don't change
const int Operator = 3; // symbols that perform operations
const int Symbol = 4; // special characters that are part of syntax
const int Error = 5; // invalid characters that are encountered
const int End = 6; // end of file input

// Token structure
struct Token {
    std::string lexeme;
    int type;
};

// Keywords, operators, and symbols
std::vector<std::string> keywords = {"int", "for", "float"};
std::vector<char> operators = {'+', '-', '*', '/', '=', '<'};
std::vector<char> symbols = {'(', ')', '{', '}', ';', ','};

// Check if a word is a keyword
bool isKeyword(const std::string& word) {
    return std::find(keywords.begin(), keywords.end(), word) != keywords.end();
}

// Check if a character is an operator
bool isOperator(char oper) {
    return std::find(operators.begin(), operators.end(), oper) != operators.end();
}

// Check if a character is a symbol
bool isSymbol(char symb) {
    return std::find(symbols.begin(), symbols.end(), symb) != symbols.end();
}

// Lexical Analyzer
std::vector<Token> LexicalAnalyzer(const std::string& input) {
    std::vector<Token> tokens;
    std::string current;

    for (size_t i = 0; i < input.length(); i++) {
        char c = input[i]; // individual characters

        if (std::isspace(c)) {
            continue; // we ignore white space
        } else if (std::isalpha(c)) {
            current.clear();
            while (std::isalnum(c) || c == '_') {
                current += c;
                c = input[++i]; // Increment inside the loop
            }
            i--;
            if (isKeyword(current)) {
                tokens.push_back({current, Keyword});
            } else {
                tokens.push_back({current, Identifier});
            }
        } else if (std::isdigit(c)) {
            current.clear();
            while (std::isdigit(c)) {
                current += c;
                c = input[++i]; // Increment inside the loop
            }
            i--;
            tokens.push_back({current, Constant});
        } else if (isOperator(c)) {
            current = c;
            tokens.push_back({current, Operator});
        } else if (isSymbol(c)) {
            current = c;
            tokens.push_back({current, Symbol});
        } else {
            tokens.push_back({std::string(1, c), Error});
        }
    }
    return tokens;
}

// Recursive-Descending Parser
size_t currentToken = 0;
std::vector<Token> tokens;

void error(const std::string& message) {
    std::cerr << "Syntax Error: " << message << std::endl;
}

bool match(int expectedType) {
    if (currentToken < tokens.size() && tokens[currentToken].type == expectedType) {
        currentToken++;
        return true;
    }
    return false;
}

bool expr() {
    if (match(Identifier) && match(Operator) && match(Identifier)) {
        return match(Constant);
    }
    error("Invalid expression.");
    return false;
}

bool assign() {
    if (match(Identifier) && match(Operator)) {
        return match(Constant) || expr();
    }
    error("Invalid assignment.");
    return false;
}

bool forloop() {
    if (match(Keyword) && match(Symbol) && assign() && match(Symbol)) {
        return expr() && match(Symbol);
    }
    error("Invalid for loop.");
    return false;
}

bool stmts() {
    if (assign()) {
        while (match(Symbol)); // Continue matching statements if present
        return true;
    }
    error("Invalid statement.");
    return false;
}

bool declares() {
    if (match(Keyword) && match(Identifier) && match(Symbol)) {
        return true;
    }
    error("Invalid declaration.");
    return false;
}

bool program() {
    if (match(Keyword) && match(Identifier) && match(Symbol) && match(Symbol)) {
        if (match(Symbol)) { // '{'
            if (declares() && stmts()) {
                return match(Symbol); // '}'
            }
        }
    }
    error("Invalid program structure.");
    return false;
}

void parse() {
    if (program()) {
        std::cout << "The program is generated by the grammar" << std::endl;
    } else {
        std::cout << "The program cannot be generated by the EBNF Described Language" << std::endl;
    }
}

int main() {
    std::ifstream inputFile("test.txt");
    std::string line;
    std::string program;

    if (inputFile.is_open()) {
        while (std::getline(inputFile, line)) {
            program += line + '\n';
        }
        inputFile.close();
    }

    tokens = LexicalAnalyzer(program);
    std::cout << "Lexemes and Tokens: " << std::endl;
    for (const auto& token : tokens) {
        std::cout << "Lexeme: " << token.lexeme << " | Token Type: " << token.type << std::endl;
    }

    parse();

    return 0;
}
